fullnameOverride: prometheus
# Required for subcharts like Grafana
ingress:
  enabled: true

alertmanager:
  fullnameOverride: alertmanager
  ingress:
    enabled: true
    ingressClassName: "nginx"
    hosts:
      - alertmanager.shakir.cloud
  # show logs in alerts
  route:
    routes: []
  templates:
    - /etc/alertmanager/config/*.tmpl
  receivers:
    - name: loki-receiver
      webhook_configs:
        - url: http://loki-stack.monitoring.svc.cluster.local:3100/loki/api/v1/push

grafana:
  enabled: true
  fullnameOverride: grafana
  defaultDashboardsEnabled: true
  defaultDashboardsTimezone: "America/Los_Angeles"
  serviceMonitor:
    enabled: true
  admin:
    existingSecret: grafana-admin-credentials
    userKey: admin-user
    passwordKey: admin-password
  ingress:
    enabled: true
    ingressClassName: "nginx"
    hosts:
      - grafana.shakir.cloud
  # allows pod auto-discovery when a pod is labeled with: metadata.labels.grafana_dashboard: "1"
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
    datasources:
      enabled: true

  # Grafana data sources
  additionalDataSources:
    - name: Prometheus
      uid: prometheus
      type: prometheus
      access: proxy
      url: http://prometheus-prometheus.monitoring.svc.cluster.local:9090
      isDefault: true

    - name: Loki-Stack
      uid: loki-stack
      type: loki
      access: proxy
      url: http://loki-stack.monitoring.svc.cluster.local:3100
      isDefault: true

prometheus:
  enabled: true
  ingress:
    enabled: true
    ingressClassName: "nginx"
    hosts:
      - prometheus.shakir.cloud
  prometheusSpec:
    replicas: 1
    replicaExternalLabelName: "replica"
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false
    retention: 24h
    enableAdminAPI: true
    walCompression: true
    scrapeInterval: 30s
    evaluationInterval: 30s
    # enable scraping across all namespaces
    serviceMonitorNamespaceSelector: {}
    podMonitorNamespaceSelector: {}
    probeNamespaceSelector: {}
    # helps with dashboard drill-downs like node -> pod -> container navigation
    scrapeMetadata: true

prometheusOperator:
  enabled: true
  prometheusConfigReloader:
    resources:
      requests:
        cpu: 200m
        memory: 50Mi
      limits:
        memory: 100Mi

kubeApiServer:
  enabled: true

kubelet:
  enabled: true
  serviceMonitor:
    metricRelabelings:
      - action: replace
        sourceLabels:
          - node
        targetLabel: instance
    # container cpu/memory, node filesystem, runtime, and liveness/readiness probe metrics
    https: true
    cAdvisor: true
    probes: true

kubeControllerManager:
  enabled: true
  endpoints:
    - 10.10.50.40

coreDns:
  enabled: true

kubeDns:
  enabled: false

kubeEtcd:
  enabled: true
  endpoints:
    - 10.10.50.40
  service:
    enabled: true
    port: 2381
    targetPort: 2381

kubeScheduler:
  enabled: true
  endpoints:
    - 10.10.50.40

kubeProxy:
  enabled: true
  endpoints:
    - 10.10.50.40

kubeStateMetrics:
  enabled: true

kube-state-metrics:
  fullnameOverride: kube-state-metrics
  selfMonitor:
    enabled: true
  prometheus:
    monitor:
      enabled: true
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node

nodeExporter:
  enabled: true
  serviceMonitor:
    relabelings:
      - action: replace
        regex: (.*)
        replacement: $1
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: kubernetes_node

prometheus-node-exporter:
  fullnameOverride: node-exporter
  podLabels:
    jobLabel: node-exporter
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
  service:
    portName: http-metrics
  prometheus:
    monitor:
      enabled: true
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node
  resources:
    requests:
      memory: 512Mi
      cpu: 250m
    limits:
      memory: 2048Mi

defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: true
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
    # The following rules are commonly used for Node Memory monitoring:
    # - nodeMemoryUtilization: Alerts on high memory usage
    # - nodeMemoryAvailable: Alerts when available memory is low
    # - nodeMemorySwap: Alerts on swap usage
    # These are typically included when `node` and `nodeExporterAlerting` are enabled,
    # but you can explicitly enable them if your chart supports it:
    nodeMemoryUtilization: true
    nodeMemoryAvailable: true
    nodeMemorySwap: true

# lokiStack:
#   grafana:
#     enabled: false # you already have Grafana
#   promtail:
#     enabled: true
#     extraScrapeConfigs: []
